{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecbae36-17ba-438f-9dce-6cf8e7881b4b",
   "metadata": {},
   "source": [
    "# French elections 2017 & 2022 \n",
    "Retrieve and parse oficials XML files of https://www.interieur.gouv.fr and https://www.resultats-elections.interieur.gouv.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a52dffb-4042-470d-9720-bea7469a624a",
   "metadata": {},
   "source": [
    "## Choose election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2589697f-d32c-479c-b481-f6aaec1d8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELECTION = 'PR2017_T2'   # PR2022_T1   PR2017_T1  PR2017_T2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6c406-f992-4183-a32d-0211d2eb003c",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = {\n",
    "    'PR2022_T1' : 'https://www.resultats-elections.interieur.gouv.fr/telechargements/PR2022/resultatsT1/',\n",
    "    'PR2017_T1' : \"https://www.interieur.gouv.fr/avotreservice/elections/telechargements/PR2017/resultatsT1/\",\n",
    "    'PR2017_T2' : \"https://www.interieur.gouv.fr/avotreservice/elections/telechargements/PR2017/resultatsT2/\"\n",
    "}\n",
    "dossier = urls[ELECTION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d974ce-4324-4b83-b42b-14f311aa1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install lxml xmltodict\n",
    "!pip3 install jmespath\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98dfa0-8414-4aee-a9f4-ab275e4e64f5",
   "metadata": {},
   "source": [
    "## Retrieve and parse index.xml file in order to create the file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccad534-f7d2-4899-b9dd-2b8f1cb017aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pd.read_xml(dossier +'index.xml', xpath='/Election/Departements/Departement', encoding='windows-1252')\n",
    "index.head(10)\n",
    "\n",
    "# fix le pb du code region qui n'a pas 3 carac, et fait une liste propres des fichiers qu'il faudra parser\n",
    "regions = list(index.CodReg3Car.unique())\n",
    "regions2 = []\n",
    "for region in regions:\n",
    "    region2 = str(region)\n",
    "    if len(region2) <3:\n",
    "        region2 = '0'+region2\n",
    "    if len(region2) <3:\n",
    "        region2 = '0'+region2\n",
    "    regions2.append(region2)\n",
    "print(region2)\n",
    "fix = pd.DataFrame({'CodReg3Car':regions,'CodReg3CarFix':regions2})\n",
    "fichiers = index.merge(fix, how='left', on='CodReg3Car')[['CodDpt','CodDpt3Car','CodReg3CarFix','LibDpt']]\n",
    "fichiers.query('CodDpt==\"13\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a41c5-5d3e-4cca-938c-4c8009c09289",
   "metadata": {},
   "source": [
    "## Parse files, by departement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3481a803-0204-4506-b6af-8847ecf01d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import xmltodict, jmespath\n",
    "\n",
    "def treat_dpt(code_region, code_dpt3, code_dpt, libelle_dpt, base_url):\n",
    "    \"\"\"Prend en entrées les informations sur le fichier à traiter, et retourne 2 dataframes: \n",
    "    - les meta données des communes (participation, nuls, blancs, ...)\n",
    "    - les résultats des candidats\n",
    "    \"\"\"\n",
    "    if code_dpt == 'ZW':\n",
    "        # ! walis et futuna ne fonctionne pas\n",
    "        return None\n",
    "    \n",
    "    #corrige les domtom\n",
    "    if code_dpt in 'ZA,ZB,ZC,ZD,ZS,ZM,ZX'.split(','):\n",
    "        dpt_pour_insee = '97'\n",
    "    elif code_dpt == 'ZZ':\n",
    "        dpt_pour_insee = 'ZZ'\n",
    "    else:\n",
    "        dpt_pour_insee = code_dpt\n",
    "    print(code_dpt, code_dpt3, '==>', dpt_pour_insee)\n",
    "    \n",
    "    #créé l'url du fichier, le récupère, et le transforme en dictionnaire\n",
    "    f = f\"{base_url}{code_region}/{code_dpt3}/{code_dpt3}{'' if code_dpt=='ZZ' else 'com'}.xml\"\n",
    "    print(code_region, code_dpt3, code_dpt, libelle_dpt, f)\n",
    "    urllib.request.urlretrieve(f, \"gitignore_fichier.xml\")\n",
    "    xml_data = open('gitignore_fichier.xml', 'r').read()  # Read data\n",
    "    data = xmltodict.parse(xml_data)  # Parse XML\n",
    "    \n",
    "    #liste des communes\n",
    "    if code_dpt == 'ZZ' :\n",
    "        print('fr etrangers')\n",
    "        communes = [jmespath.search('Election.Departement', data)]\n",
    "        first_commune_path = 'Election.Departement.'\n",
    "    else:\n",
    "        communes = jmespath.search('Election.Departement.Communes.Commune[:]', data)\n",
    "        first_commune_path = 'Election.Departement.Communes.Commune[0:1].'\n",
    "    \n",
    "    #prend le bon tour\n",
    "    tours_tmp = jmespath.search(first_commune_path+'Tours.Tour[-1]', data)\n",
    "    tour = 'Tours.Tour' if (tours_tmp == None or len(tours_tmp) == 0) else 'Tours.Tour[-1]'\n",
    "    \n",
    "    #liste des candidats\n",
    "    candidats = jmespath.search(first_commune_path + tour + '.Resultats.Candidats.Candidat[:].NomPsn', data) \n",
    "    if type(candidats[0]) == list:\n",
    "        candidats = candidats[0]\n",
    "    nb_candidats = len(candidats)\n",
    "    \n",
    "    #boucle sur les communes pour créer les dataframes de participation (blancs, nuls, ...) et de résultat\n",
    "    dfs_participations = []\n",
    "    dfs_resultats = []\n",
    "    for commune in communes:\n",
    "        get = lambda r:jmespath.search(r,commune)\n",
    "        code_commune = get('CodSubCom') \n",
    "        \n",
    "        #fix pour mayotte dans les résulats 2017 ...\n",
    "        if libelle_dpt == 'Mayotte' and int(code_commune) <600:\n",
    "            code_commune = str(int(code_commune) + 100) \n",
    "        code_insee = dpt_pour_insee if get('CodSubCom') == None else dpt_pour_insee + code_commune\n",
    "\n",
    "        # ! ignore les données relatives aux arrondissements et aux sections pour ne pas avoir de doublons\n",
    "        if 'AR' in code_insee or 'SR' in code_insee:\n",
    "            continue\n",
    "        \n",
    "        #données de participation / blanc / nuls \n",
    "        meta_communes = pd.DataFrame({\"code_dpt\":[code_dpt],\\\n",
    "                                    'libelle_dpt':[libelle_dpt],\\\n",
    "                                      'code_insee':[code_insee],\\\n",
    "                         'commune':[get('LibSubCom') or ''],\\\n",
    "                         'votants':[get(tour+'.Mentions.Votants.Nombre')],\\\n",
    "                         'inscrits':[get(tour+'.Mentions.Inscrits.Nombre')],\\\n",
    "                         'nuls':[get(tour+'.Mentions.Nuls.Nombre')], \\\n",
    "                         'blancs':[get(tour+'.Mentions.Blancs.Nombre')],\\\n",
    "                        'exprimes':[get(tour+'.Mentions.Exprimes.Nombre')]}).set_index('code_insee')\n",
    "\n",
    "        #force les résulats en numeric\n",
    "        for col in ['votants','inscrits','nuls','blancs','exprimes']:\n",
    "            meta_communes[col] = pd.to_numeric(meta_communes[col], errors='coerce')\n",
    "        dfs_participations.append(meta_communes)\n",
    "        \n",
    "        #resultat des candidats\n",
    "        resultats = pd.DataFrame({ 'code_insee':[code_insee]*nb_candidats,\n",
    "                         'candidat':get(tour+'.Resultats.Candidats.Candidat[:].NomPsn'), \n",
    "                         'nb_voix':get(tour+'.Resultats.Candidats.Candidat[:].NbVoix')})\n",
    "        resultats['nb_voix'] = pd.to_numeric(resultats['nb_voix'], errors='coerce')\n",
    "        dfs_resultats.append(resultats)\n",
    "                                   \n",
    "    communes = pd.concat(dfs_participations)\n",
    "    resultats = pd.concat(dfs_resultats)\n",
    "    \n",
    "    return (communes,resultats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cc807c-1f2c-440a-8dd1-57fb65645ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boucle sur les départemennts et aggrege les données\n",
    "dfs_communes_dpt = []\n",
    "dfs_resultats_dpt = []\n",
    "data = {}\n",
    "def one_file(df):\n",
    "    #try:\n",
    "    res = treat_dpt(code_region=df.CodReg3CarFix, code_dpt3=df.CodDpt3Car, code_dpt=df.CodDpt, \\\n",
    "                                 libelle_dpt=df.LibDpt, base_url=dossier)\n",
    "    if res == None:\n",
    "        return\n",
    "    (communes,resultats) = res\n",
    "    dfs_communes_dpt.append(communes)\n",
    "    dfs_resultats_dpt.append(resultats)\n",
    "    #except: \n",
    "    #    print('pb avec'+df.CodDpt)\n",
    "fichiers.apply(one_file, axis=1) #  .query('CodDpt==\"ZZ\"')\n",
    "\n",
    "df_communes = pd.concat(dfs_communes_dpt)\n",
    "df_resultats = pd.concat(dfs_resultats_dpt)\n",
    "\n",
    "# ! il y a toujours un pb à corriger avec Walis et Futuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991082b6-1231-4665-86dd-523e3ffded05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_communes.query('commune == \"Franconville\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7bff13-866f-44cf-b146-a1606f4e30e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidats = list(df_resultats.candidat.unique())\n",
    "df_resultats.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52af39-c99a-42a9-93b3-7ff3dc2c84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vérification qu'il n'y a pas d'erreurs dans les code de commune des fichiers xml (ça arrive...)\n",
    "df = df_communes.reset_index()\n",
    "df[df.duplicated(subset='code_insee')]\n",
    "#df.query('code_insee == \"97501\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e420fe2-3c2e-4d23-bc4d-a949066d0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crée un fichier avec 1 ligne par commune et 1 colonne par candidat\n",
    "resultats_pivot = df_resultats.pivot(index='code_insee',columns='candidat',values='nb_voix')\n",
    "out = df_communes.merge(resultats_pivot, left_index=True, right_index=True)\n",
    "out.head(3)\n",
    "out.to_csv('gitignore_elections_'+ELECTION+'_brutes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53259a96-b594-4a36-a06a-dca31fec49fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#affiche les résultats\n",
    "conf_agg = {}\n",
    "for candidat in candidats:\n",
    "    conf_agg[candidat] = 'sum' \n",
    "100.0 * out.agg(conf_agg) / out.exprimes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36595ec7-abd8-45dc-92e2-7e9db1825aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fd058f-d7e9-461f-8b4d-de96ad416f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
